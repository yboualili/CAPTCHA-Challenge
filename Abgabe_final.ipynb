{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680a6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93493cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from cv2 import dnn_superres\n",
    "from torch import nn\n",
    "from transformers import Trainer, TrainingArguments, ViTForImageClassification, ViTImageProcessor\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from datasets import load_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a583da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty datasets\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Set train-test split ratio\n",
    "split = 0.90\n",
    "\n",
    "# Path to training data\n",
    "path = \"data/train\"\n",
    "\n",
    "# Load the super-resolution model for image upscaling\n",
    "sr = dnn_superres.DnnSuperResImpl_create()\n",
    "path_ = \"FSRCNN_x3.pb\"\n",
    "sr.readModel(path_)\n",
    "sr.setModel(\"fsrcnn\", 3)\n",
    "\n",
    "# Preprocess images and save them in JSON format\n",
    "json_format = {}\n",
    "for ind, folder in enumerate(os.listdir(path)):\n",
    "    images_list = []\n",
    "    for image_name in os.listdir(os.path.join(path, folder)):\n",
    "        # Open and process each image\n",
    "        image = Image.open(os.path.join(path, folder, image_name)).convert('RGB')\n",
    "        image = sr.upsample(np.asarray(image))\n",
    "        image = cv2.fastNlMeansDenoisingColored(image, None, 7, 21, 16, 16)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((224, 224))\n",
    "        img_array = np.asarray(image).reshape((224, 224, 3))\n",
    "        images_list.append(img_array.tolist())\n",
    "    json_format[folder] = images_list\n",
    "\n",
    "# Save preprocessed images to a JSON file\n",
    "json.dump(json_format, open(\"full_data.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422852ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train VIT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ViT image processor\n",
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(model_name_or_path)\n",
    "\n",
    "# Load preprocessed data\n",
    "with open('data/full_data.json') as f:\n",
    "    json_load = json.load(f)\n",
    "\n",
    "# Train the ViT models in a loop\n",
    "for clf in range(0, 100):\n",
    "    print(f\"Training classifier {clf}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Prepare train and test datasets\n",
    "    x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "    for data_class in list(json_load.keys()):\n",
    "        # Determine the limit for training data using a gamma distribution\n",
    "        # every model will have a different distribution of class images and therefore different strenghts at predicting specific classes\n",
    "        limit = 0\n",
    "        while limit < 10:\n",
    "            limit = int((np.random.gamma(4, 2) + 2) * 2)\n",
    "\n",
    "        data = np.asarray(json_load[data_class])\n",
    "        if limit > len(data) - 1:\n",
    "            limit = len(data) - 1\n",
    "\n",
    "        np.random.shuffle(data)\n",
    "        train = data[:limit]\n",
    "        test = data[limit:]\n",
    "\n",
    "        x_train.extend(train)\n",
    "        y_train.extend([data_class] * len(train))\n",
    "        x_test.extend(test)\n",
    "        y_test.extend([data_class] * len(test))\n",
    "\n",
    "    print(f\"Train data shape: {np.array(x_train).shape}\")\n",
    "    print(f\"Test data shape: {np.array(x_test).shape}\")\n",
    "\n",
    "    # Convert train and test data into DataFrames\n",
    "    train_df = pd.DataFrame(\n",
    "        {\"pixel_values\": [Image.fromarray(img.astype('uint8'), 'RGB') for img in x_train], \"label\": y_train})\n",
    "    test_df = pd.DataFrame(\n",
    "        {\"pixel_values\": [Image.fromarray(img.astype('uint8'), 'RGB') for img in x_test], \"label\": y_test})\n",
    "\n",
    "    # Class labels\n",
    "    labels = os.listdir(\"data/train\")\n",
    "\n",
    "\n",
    "    # Custom PyTorch Dataset with data augmentation\n",
    "    class CustomDatasetAug(Dataset):\n",
    "        def __init__(self, images, labels):\n",
    "            self.images = images\n",
    "            self.labels = labels\n",
    "            self.datagen = ImageDataGenerator(\n",
    "                rotation_range=20,\n",
    "                zoom_range=0.15,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.15,\n",
    "                height_shift_range=0.15\n",
    "            )\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = self.images[idx]\n",
    "            label = self.labels[idx]\n",
    "            augmented_img = self.datagen.random_transform(np.array(image))\n",
    "            augmented_img = Image.fromarray(augmented_img)\n",
    "            sample = {\"image\": feature_extractor(augmented_img), \"label\": label}\n",
    "            return sample\n",
    "\n",
    "\n",
    "    # Custom PyTorch Dataset without data augmentation\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, images, labels):\n",
    "            self.images = images\n",
    "            self.labels = labels\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = self.images[idx]\n",
    "            label = self.labels[idx]\n",
    "            sample = {\"image\": feature_extractor(image), \"label\": label}\n",
    "            return sample\n",
    "\n",
    "\n",
    "    # Instantiate datasets\n",
    "    ds_train = CustomDatasetAug(train_df['pixel_values'], train_df['label'])\n",
    "    ds_test = CustomDataset(test_df['pixel_values'], test_df['label'])\n",
    "\n",
    "\n",
    "    # Custom Trainer with weighted loss for handling class imbalance\n",
    "    class CustomTrainer(Trainer):\n",
    "        def compute_loss(self, model, inputs, return_outputs=False):\n",
    "            labels = inputs.get(\"labels\")\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.get(\"logits\")\n",
    "            weights = torch.tensor([0.7, 0.5, 0.5, 0.5, 2.0, 0.5, 0.5, 2.0, 1.0, 0.5, 0.5, 0.5]).cuda()\n",
    "            loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
    "            loss = loss_fn(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "    # Compute accuracy metric\n",
    "    metric = load_metric(\"accuracy\")\n",
    "\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)\n",
    "\n",
    "\n",
    "    # Data collator for batching\n",
    "    def collate_fn(batch):\n",
    "        all_imgs = torch.stack([torch.tensor(x['image'][\"pixel_values\"][0]) for x in batch])\n",
    "        return {\n",
    "            'pixel_values': all_imgs,\n",
    "            'labels': torch.tensor([labels.index(x['label']) for x in batch])\n",
    "        }\n",
    "\n",
    "\n",
    "    # Model training configuration\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        num_labels=len(labels),\n",
    "        id2label={str(i): c for i, c in enumerate(labels)},\n",
    "        label2id={c: str(i) for i, c in enumerate(labels)}\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./vit_bagging/clf_{clf}\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        num_train_epochs=10,\n",
    "        save_steps=100,\n",
    "        eval_steps=100,\n",
    "        logging_steps=10,\n",
    "        learning_rate=1e-4,\n",
    "        save_total_limit=2,\n",
    "        lr_scheduler_type=\"cosine_with_restarts\",\n",
    "        remove_unused_columns=False,\n",
    "        load_best_model_at_end=True,\n",
    "        save_strategy=\"steps\",\n",
    "        auto_find_batch_size=True,\n",
    "        gradient_checkpointing=True\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=collate_fn,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=ds_train,\n",
    "        eval_dataset=ds_test,\n",
    "        tokenizer=feature_extractor\n",
    "    )\n",
    "\n",
    "    train_results = trainer.train()\n",
    "    trainer.save_model()\n",
    "    trainer.log_metrics(\"train\", train_results.metrics)\n",
    "    trainer.save_metrics(\"train\", train_results.metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "    # Evaluate the model\n",
    "    metrics = trainer.evaluate(ds_test)\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "    print(f\"--- {time.time() - start_time} seconds ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dbb248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained ViT model and feature extractor\n",
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(model_name_or_path)\n",
    "\n",
    "# Load the dataset\n",
    "with open('data/full_data.json') as f:\n",
    "    json_load = json.load(f)\n",
    "\n",
    "print(\"Loaded data\")\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each class in the dataset\n",
    "for data_class in list(json_load.keys()):\n",
    "    data = np.asarray(json_load[data_class])\n",
    "    \n",
    "    if len(data) > 0:\n",
    "        for i in data:\n",
    "            # Extract pixel values using the feature extractor\n",
    "            a = feature_extractor(i)[\"pixel_values\"][0]\n",
    "            imgs.append(a)\n",
    "    \n",
    "    # Create a label list for each class\n",
    "    label_list = [data_class for _ in range(len(data))]\n",
    "    labels.extend(label_list)\n",
    "\n",
    "print(f\"Total labels: {len(labels)}\")\n",
    "\n",
    "# Create a folder path for bagging models\n",
    "folder = \"vit_bagging\"\n",
    "print(\"Preprocessed\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Loop through each model in the bagging folder\n",
    "for model_path in os.listdir(folder):\n",
    "    print(f\"Processing model: {model_path}\")\n",
    "    r = []\n",
    "\n",
    "    # Process images in batches of 40\n",
    "    for i in range(40, len(imgs), 40):\n",
    "        img_batch = imgs[i-40:i]\n",
    "        model = ViTForImageClassification.from_pretrained(os.path.join(folder, model_path), local_files_only=True).cuda()\n",
    "        r.extend(model(torch.tensor(np.asarray(img_batch)).cuda()).logits.tolist())\n",
    "        l = i\n",
    "\n",
    "    # Process the remaining images\n",
    "    img_batch = imgs[l:]\n",
    "    model = ViTForImageClassification.from_pretrained(os.path.join(folder, model_path), local_files_only=True).cuda()\n",
    "    r.extend(model(torch.tensor(np.asarray(img_batch)).cuda()).logits.tolist())\n",
    "\n",
    "    all_results.append(r)\n",
    "\n",
    "# Save the results in a JSON file\n",
    "json_format = {\n",
    "    \"res\": all_results,\n",
    "    \"labels\": labels\n",
    "}\n",
    "\n",
    "with open(\"bagging_results.json\", \"w\") as f:\n",
    "    json.dump(json_format, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ccca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ae34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bagging results\n",
    "with open('bagging_results.json') as f:\n",
    "    json_load = json.load(f)\n",
    "\n",
    "data = np.asarray(json_load[\"res\"])\n",
    "labels = np.asarray(json_load[\"labels\"])\n",
    "\n",
    "# Reshape data for stacking\n",
    "a = []\n",
    "for i in range(data.shape[1]):\n",
    "    a.append([j[i] for j in data])\n",
    "\n",
    "X = np.array(a)\n",
    "print(f\"Shape of data for stacking: {X.shape}\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.array(labels), test_size=0.2, random_state=1)\n",
    "\n",
    "# Encode labels to integers\n",
    "le = LabelEncoder()\n",
    "le.fit(list(os.listdir(\"data/train\")))\n",
    "\n",
    "print(f\"Label classes: {le.classes_}\")\n",
    "\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Reshape data for LSTM model input\n",
    "X_train = X_train.reshape((2386, 98, 12))\n",
    "X_test = X_test.reshape((597, 98, 12))\n",
    "\n",
    "# Define the LSTM model\n",
    "model = models.Sequential([\n",
    "    keras.Input(shape=(98, 12)),\n",
    "    layers.LSTM(512, return_sequences=True),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.LSTM(265, return_sequences=True),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.LSTM(128, return_sequences=True),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.LSTM(128, return_sequences=True),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.LSTM(128, return_sequences=False),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(12, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Define class weights for handling class imbalance\n",
    "cls_weight = {0: 0.5, 1: 2, 2: 0.5, 3: 0.5, 4: 0.5, 5: 0.5, 6: 0.5, 7: 10, 8: 2, 9: 0.5, 10: 0.5, 11: 0.5}\n",
    "\n",
    "# Define model checkpoint callback to save the best model\n",
    "checkpoint = ModelCheckpoint(\"models/bagging-{epoch:02d}.model\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=40, validation_data=(X_test, y_test), callbacks=[checkpoint], class_weight=cls_weight)\n",
    "\n",
    "# Evaluate the model and print the classification report\n",
    "y_pred = model.predict(X_test)\n",
    "res = [np.argmax(i) for i in y_pred]\n",
    "\n",
    "print(classification_report(y_test, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ebbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa551f1",
   "metadata": {},
   "outputs": [],
   "source": "# Preprocess Test Data for Bagging"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86269e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "all_imgs = []\n",
    "all_filenames = []\n",
    "\n",
    "test_folder = r\"C:\\Users\\Admin\\Downloads\\Captcha Dateien\\Captcha Dateien\\test\\test_data\\test\"\n",
    "\n",
    "# Loop through test data files\n",
    "for i in range(9):\n",
    "    with open(f'test/x_test{i}.json') as f:\n",
    "        json_load = json.load(f)\n",
    "        images = np.asarray(json_load[\"X_test\"])\n",
    "        file_names = list(json_load[\"filenames\"])\n",
    "        all_imgs.extend(images)\n",
    "        all_filenames.extend(file_names)\n",
    "\n",
    "print(\"Loaded test data\")\n",
    "\n",
    "# Preprocess test images\n",
    "imgs = [feature_extractor(im)[\"pixel_values\"][0] for im in all_imgs]\n",
    "\n",
    "print(\"Preprocessed test images\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Loop through each model in the bagging folder\n",
    "for model_path in os.listdir(folder):\n",
    "    print(f\"Processing model: {model_path}\")\n",
    "    r = []\n",
    "\n",
    "    # Process images in batches of 40\n",
    "    for i in range(40, len(imgs), 40):\n",
    "        img_batch = imgs[i-40:i]\n",
    "        model = ViTForImageClassification.from_pretrained(os.path.join(folder, model_path), local_files_only=True).cuda()\n",
    "        r.extend(model(torch.tensor(np.asarray(img_batch)).cuda()).logits.tolist())\n",
    "        l = i\n",
    "\n",
    "    # Process remaining images\n",
    "    img_batch = imgs[l:]\n",
    "    model = ViTForImageClassification.from_pretrained(os.path.join(folder, model_path), local_files_only=True).cuda()\n",
    "    r.extend(model(torch.tensor(np.asarray(img_batch)).cuda()).logits.tolist())\n",
    "\n",
    "    all_results.append(r)\n",
    "\n",
    "# Save the results in a JSON file\n",
    "json_format = {\n",
    "    \"res\": all_results,\n",
    "    \"filenames\": all_filenames\n",
    "}\n",
    "\n",
    "with open(\"bagging_results_test_more.json\", \"w\") as f:\n",
    "    json.dump(json_format, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d061c93",
   "metadata": {},
   "outputs": [],
   "source": "#Predict Test Data and Save Results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b749ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bagging results\n",
    "with open('bagging_results_test_more.json') as f:\n",
    "    json_load = json.load(f)\n",
    "\n",
    "data = np.asarray(json_load[\"res\"])\n",
    "labels = np.asarray(json_load[\"filenames\"])\n",
    "\n",
    "# Prepare data for prediction\n",
    "a = []\n",
    "for i in range(data.shape[1]):\n",
    "    a.append([j[i] for j in data])\n",
    "\n",
    "X_test = np.array(a)\n",
    "\n",
    "# Loop through relevant models and make predictions\n",
    "for model_name in os.listdir(\"relevant_models\"):\n",
    "    if model_name in [\"dense_1\", \"dense_2\"]:\n",
    "        X_test_reshaped = X_test.reshape((8730, 98, 12, 1))\n",
    "    else:\n",
    "        X_test_reshaped = X_test.reshape((8730, 98, 12))\n",
    "\n",
    "    # Load the trained model\n",
    "    model = keras.models.load_model(os.path.join(\"relevant_models\", model_name))\n",
    "\n",
    "    # Create a DataFrame to store the predictions\n",
    "    output_labels = [\"ImageName\"] + list(os.listdir(\"data/train\"))\n",
    "    csv_df = pd.DataFrame(columns=output_labels)\n",
    "\n",
    "    # Make predictions for each image\n",
    "    for ind, img in enumerate(X_test_reshaped):\n",
    "        t = np.array([img])\n",
    "        logits = list(model.predict(t)[0])\n",
    "        output = [labels[ind]] + logits\n",
    "        csv_df.loc[len(csv_df)] = output\n",
    "\n",
    "    # Save predictions to CSV\n",
    "    csv_df.to_csv(f\"new_bagging_outputs/{model_name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
